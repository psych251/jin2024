---
title: "Replication of 'Two faces of holistic face processing: Facilitation and interference underlying part-whole and composite effects' by Jin, Hayward, & Cheung (2024, Journal of Vision)"
author: "Seojin Lee (seojinl@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

### Justification 
My research interests lie in human visual perception, particularly in understanding how the brain integrates low-level information from complex visual input to achieve higher-level understanding of the object. Face is a great example of this, as it involves integrating smaller visual fragments such as eyes, nose, and mouth to achieve an understanding of the identity. The complete composite task from Jin, Hayward, & Cheung (2024) offers a well-defined behavioral paradigm to study this integration process. Specifically, it separates two components of holistic processing -- facilitation and interference, rather than a single, unified holistic effect. Replicating this effect will deepen my understanding of face perception mechanisms. 

### Stimuli and Procedure
This replication focuses on the **complete composite task**. In the task, participant judged whether the top half of a composite face matched with the top half of previously shown face while ignoring the bottom half. In the *aligned-congruent condition*, both halves were from the same identity, while in the *aligned-incongruent condition*, the bottom half came from a different identity. Performance in these conditions was compared to an *isolated (top-only)* baseline. In the original study, facilitation was observed when congruent information improved performance, while interference emerged when incongruent information impaired performance. The effects was seen across both *d'* (accuracy) and reaction times. As in the original study, the task will be implemented online using jsPsych and hosted on Prolific. Stimuli will be grayscale composite faces drawn from open databases (Chicago Face Database). Each trial will display two faces (500 ms each) and participants will respond using keyboard keys ("S" for same, "D" for different).

Potential challenges include implementing the online experiment. Although the authors described the experimental structure in detail (stimulus type, timing, and response method), they did not provide their jsPsych code. I plan to replicate the task myself using standardized face stimuli from the Chicago Face Database, to match the original design. Another challenge involves the analysis using R. Since I have limited experience with R, I expect a learning curve in data processing and mixed-effects modeling. I plan to rely on existing example scripts from the original paper's repo and R tutorials. 


### Links to repos 
* Replication repository: https://github.com/psych251/jin2024
* Original paper: https://jov.arvojournals.org/article.aspx?articleid=2802147


## Methods

### Power Analysis

Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.

The original study reported a large facilitation (*z* = 10.17, *p* < 0.001) and interference (*z* = -20.33, *p* < 0.001) effects in accuracy. 

### Planned Sample

Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.

### Materials

All materials - can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.

### Procedure	

Can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.

### Analysis Plan

Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.

### Differences from Original Study

Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study.  The goal, of course, is to minimize those differences, but differences will inevitably occur.  Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
### Data Preparation

#### Load Relevant Libraries and Functions

#### Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
